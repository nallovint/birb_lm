GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama3-8b-8192

# Choose ONE
# LLM_MODE=ollama
LLM_MODE=groq

# If using Ollama/local OpenAI-compatible
LLM_BASE_URL=http://ollama:11434
# LLM_MODEL=llama3.2:1b
LLM_MODEL=llama3.1:8b     #Â docker compose exec ollama ollama pull llama3.1:8b
